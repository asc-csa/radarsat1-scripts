{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c04769b4",
   "metadata": {},
   "source": [
    "# Classification Using Measurement Data\n",
    "\n",
    "This notebook contains a basic classification that analyzes the lake ice measurements provided by Environment and Climate Change Canada and the Canadian Ice Service program.\n",
    "\n",
    "This was done as part of exploratory work into using this dataset with basic machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b2f210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages for data analysis and machine learning\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77619528",
   "metadata": {},
   "source": [
    "We start by reading the lake ice measurements from the file. We create a \"HAS_ICE\" column that determines whether a measurement has ice or not, which can then be used for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38ddc240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>NAME</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LONG</th>\n",
       "      <th>ICE_COVER</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1995-11-17</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>Rainy Lake</td>\n",
       "      <td>48.6</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1995-11-17</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>Gods Lake</td>\n",
       "      <td>54.7</td>\n",
       "      <td>94.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1995-11-17</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>Lake Nipissing</td>\n",
       "      <td>46.3</td>\n",
       "      <td>79.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1995-11-17</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>Lake Nipigon</td>\n",
       "      <td>49.8</td>\n",
       "      <td>88.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1995-11-17</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>Baker Lake</td>\n",
       "      <td>64.2</td>\n",
       "      <td>95.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1995-11-17</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>Yuthkyed Lake</td>\n",
       "      <td>62.7</td>\n",
       "      <td>97.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1995-11-17</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>Island Lake</td>\n",
       "      <td>53.8</td>\n",
       "      <td>94.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1995-11-17</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>Red Lake</td>\n",
       "      <td>48.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1995-11-17</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>Lake Simcoe</td>\n",
       "      <td>44.4</td>\n",
       "      <td>79.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1995-11-17</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>Nettilling Lake</td>\n",
       "      <td>66.5</td>\n",
       "      <td>70.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID       DATE    TIME             NAME   LAT  LONG  ICE_COVER  YEAR  \\\n",
       "0   1.0 1995-11-17  2130.0       Rainy Lake  48.6  93.0        0.0  1995   \n",
       "1   2.0 1995-11-17  2130.0        Gods Lake  54.7  94.3       10.0  1995   \n",
       "2   3.0 1995-11-17  2130.0   Lake Nipissing  46.3  79.7        0.0  1995   \n",
       "3   4.0 1995-11-17  2130.0     Lake Nipigon  49.8  88.5        0.0  1995   \n",
       "4   5.0 1995-11-17  2130.0       Baker Lake  64.2  95.4       10.0  1995   \n",
       "5   6.0 1995-11-17  2130.0    Yuthkyed Lake  62.7  97.9       10.0  1995   \n",
       "6   7.0 1995-11-17  2130.0      Island Lake  53.8  94.5       10.0  1995   \n",
       "7   8.0 1995-11-17  2130.0         Red Lake  48.0  95.0        0.0  1995   \n",
       "8   9.0 1995-11-17  2130.0      Lake Simcoe  44.4  79.3        0.0  1995   \n",
       "9  10.0 1995-11-17  2130.0  Nettilling Lake  66.5  70.5       10.0  1995   \n",
       "\n",
       "   MONTH  \n",
       "0     11  \n",
       "1     11  \n",
       "2     11  \n",
       "3     11  \n",
       "4     11  \n",
       "5     11  \n",
       "6     11  \n",
       "7     11  \n",
       "8     11  \n",
       "9     11  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_excel('lakeice-measurements.xlsx')\n",
    "X['YEAR'] = X['DATE'].dt.year\n",
    "X['MONTH'] = X['DATE'].dt.month\n",
    "X['HAS_ICE'] = X['ICE_COVER'] > 0.5\n",
    "y = X.pop(\"HAS_ICE\").values\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2740ab0",
   "metadata": {},
   "source": [
    "We then create a feature set, using the latitude, longitude, year and month of the lake measurements as features. We then randomly split the data into a training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "495fa173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting the dataset...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "featureSet = ['LAT', 'LONG', 'YEAR', 'MONTH']\n",
    "X = X[featureSet].copy()\n",
    "\n",
    "# split the large dataset into train and test\n",
    "print(\"Splitting the dataset...\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state=2)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396caaff",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "We can then apply a Naive Bayes algorithm to see if it can be trained on the data well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b27fbdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to calculate accuracy\n",
    "def accuracy(actualTags, predictions):\n",
    "    totalFound = 0\n",
    "    for i in range(len(actualTags)):\n",
    "        if (actualTags[i] == predictions[i]):\n",
    "            totalFound += 1\n",
    "    return totalFound / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf5da6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the NB classifier...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the NB classifier...\")\n",
    "clf_nb = MultinomialNB().fit(X_train, y_train)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7d2947",
   "metadata": {},
   "source": [
    "We can then use the trained classifier to predict the results of the data it was trained on. Then, we use it to predict the results of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68089000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True  True  True False  True False False  True]\n",
      "0.7603099937731164\n"
     ]
    }
   ],
   "source": [
    "training_predictions = clf_nb.predict(X_train)\n",
    "print(training_predictions[0:10])\n",
    "print(accuracy(y_train, training_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f897328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False  True False  True  True False False False  True]\n",
      "0.7603228904093146\n"
     ]
    }
   ],
   "source": [
    "testing_predictions = clf_nb.predict(X_val)\n",
    "print(testing_predictions[0:10])\n",
    "print(accuracy(y_val, testing_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b21950b",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Same as the Naive Bayes algorithm but using a Logistic Regression algorithm instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19609bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the LR classifier...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the LR classifier...\")\n",
    "clf_lr = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1).fit(X_train, y_train)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51d84b6",
   "metadata": {},
   "source": [
    "We can then test it on the training and test data, as well as create a set of predictions for the year 2013 at a given latitude and longitude (sample case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "696a2b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True  True False False  True  True False  True]\n",
      "0.739963839061316\n"
     ]
    }
   ],
   "source": [
    "training_predictions_lr = clf_lr.predict(X_train)\n",
    "print(training_predictions_lr[0:10])\n",
    "print(accuracy(y_train, training_predictions_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43824f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False  True False  True  True False False False  True]\n",
      "0.737426479414236\n"
     ]
    }
   ],
   "source": [
    "testing_predictions_lr = clf_lr.predict(X_val)\n",
    "print(testing_predictions_lr[0:10])\n",
    "print(accuracy(y_val, testing_predictions_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "465367f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True, False, False, False, False,\n",
       "       False, False, False])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[45, 75, 2013, 1], [45, 75, 2013, 2], [45, 75, 2013, 3], [45, 75, 2013, 4], [45, 75, 2013, 5], [45, 75, 2013, 6], [45, 75, 2013, 7], [45, 75, 2013, 8], [45, 75, 2013, 9], [45, 75, 2013, 10], [45, 75, 2013, 11], [45, 75, 2013, 12]]\n",
    "df_test = pd.DataFrame(data, columns = ['LAT', 'LONG', 'YEAR', 'MONTH'])\n",
    "clf_nb.predict(df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
